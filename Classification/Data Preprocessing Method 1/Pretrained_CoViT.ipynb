{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_vit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sqwSFTOk5VQ",
        "outputId": "7112515f-7730-4f67-f339-940d6d3444ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_vit in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch_pretrained_vit) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch_pretrained_vit) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch_pretrained_vit) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch_pretrained_vit) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch_pretrained_vit) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch_pretrained_vit) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SHJDyiS7PQ7v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import math\n",
        "import numpy\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torchvision.models.vision_transformer import VisionTransformer\n",
        "from pytorch_pretrained_vit import ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSKVDATbPcwZ",
        "outputId": "62ed9423-6387-4479-8674-a77441b40e37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f29a85b61f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.manual_seed(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVjymfmCPm4X",
        "outputId": "4f326b03-27b9-43c9-c150-3b0b3bf475e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xyi6_qudPoGX"
      },
      "outputs": [],
      "source": [
        "# Directory Names\n",
        "dir_training = './drive/MyDrive/inlay_onlay_dataset/training'\n",
        "dir_validation = './drive/MyDrive/inlay_onlay_dataset/validation'\n",
        "dir_testing = './drive/MyDrive/inlay_onlay_dataset/testing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HYJagPZOQeeM"
      },
      "outputs": [],
      "source": [
        "class ToothDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.dataset_path = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.dataset_path))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx  >= len(os.listdir(self.dataset_path)):\n",
        "            print(\"No datafile/image at index : \"+ str(idx))\n",
        "            return None\n",
        "        npy_filename = os.listdir(self.dataset_path)[idx]\n",
        "        label = int('onlay' in npy_filename)\n",
        "        numpy_arr = numpy.load(self.dataset_path + '/' + npy_filename)\n",
        "        for i in range(numpy_arr.shape[0]-70): numpy_arr = numpy.delete(numpy_arr, [0], axis=0)\n",
        "        numpy_arr = numpy_arr.reshape(1, 70, 70, 70)\n",
        "        tensor_arr = torch.from_numpy(numpy_arr).to(torch.float32)\n",
        "\n",
        "        del numpy_arr\n",
        "        gc.collect()\n",
        "\n",
        "        if self.transform: tensor_arr = self.transform(tensor_arr) # Apply transformations\n",
        "\n",
        "        return tensor_arr.to(torch.float32), torch.LongTensor([label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nr398yHVQhxT"
      },
      "outputs": [],
      "source": [
        "training_data = ToothDataset(img_dir=dir_training, transform=None)\n",
        "validation_data = ToothDataset(img_dir=dir_validation, transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the pretrained weights\n",
        "pretrained_vit = ViT('B_16_imagenet1k', pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxATr_t_9-F",
        "outputId": "03aec789-c3b9-4881-9d0b-67a6550a41d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the ViT\n",
        "for param in pretrained_vit.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "qELp-dSGBmJA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RwH1qXktQlOd"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # The CNN layers with maxpool and ReLU\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv3d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2),\n",
        "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2),\n",
        "            nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2),\n",
        "            nn.Conv3d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2),\n",
        "            nn.Conv3d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=2),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        # Pretrained ViT\n",
        "        self.vit = pretrained_vit\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1000,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512,2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "\n",
        "        # Reshape the CNN output (output of size batch*4096) into batch*3x384x384\n",
        "        x = x.repeat(1, 36, 1, 1, 1)\n",
        "        x = x.view(-1, 1, 384, 384)\n",
        "        x = x.repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Pass the reshaped CNN output into ViT\n",
        "        x = self.vit(x)\n",
        "\n",
        "        # Pass it into the fully connected layers\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sRE_KuDDQnKG"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tszA-R18lGgS",
        "outputId": "6c076cb9-d0c1-4396-9af7-112645665193"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0287, 0.2092]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Checking a forward pass, if no error is detected, then eveything is okay\n",
        "single_training_sample = training_data[0][0].reshape(1,1,70,70,70).to(device)\n",
        "model(single_training_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Rju3Y47LQoaJ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "epochs = 15\n",
        "batch_size = 2\n",
        "learning_rate = 1e-6\n",
        "weight_decay = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iTnpPGvRQqiu"
      },
      "outputs": [],
      "source": [
        "loss_function=nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam( model.parameters()  ,lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GINVboKiQr4k"
      },
      "outputs": [],
      "source": [
        "training_data_loader = DataLoader(training_data, batch_size, shuffle = True)\n",
        "validation_data_loader = DataLoader(validation_data, batch_size, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j-XRPMtkQtM7"
      },
      "outputs": [],
      "source": [
        "# The training function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    torch.cuda.empty_cache()\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.squeeze())\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch%5==0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "        del pred\n",
        "        del loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qHD2Fgd2Qum-"
      },
      "outputs": [],
      "source": [
        "# Keep record of the validation accuracy\n",
        "validation_accuracy = []\n",
        "\n",
        "# The validation function\n",
        "def validation(dataloader, model, loss_fn):\n",
        "    global validation_accuracy\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.squeeze()).item()\n",
        "            correct += (torch.argmax(pred, dim=1) == y.squeeze()).sum().item()\n",
        "            X.cpu()\n",
        "            y.cpu()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    # Keep record of the validation accuracy globally\n",
        "    validation_accuracy.append(correct*100)\n",
        "    # Print\n",
        "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(f\"Current best validation accuracy: {max(validation_accuracy)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCMkki52Qx9_",
        "outputId": "6187cf36-4051-4aa7-8376-76860aeaf379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.828423  [    0/   20]\n",
            "loss: 0.637491  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.675662 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.570743  [    0/   20]\n",
            "loss: 0.796301  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.672706 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.626618  [    0/   20]\n",
            "loss: 0.644107  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.670998 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.819908  [    0/   20]\n",
            "loss: 0.573188  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.669826 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.662102  [    0/   20]\n",
            "loss: 0.886220  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.669390 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.713577  [    0/   20]\n",
            "loss: 0.626037  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.668157 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.816963  [    0/   20]\n",
            "loss: 0.718557  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.666869 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.689079  [    0/   20]\n",
            "loss: 0.600084  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.665248 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.761190  [    0/   20]\n",
            "loss: 0.782085  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.665186 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.797080  [    0/   20]\n",
            "loss: 0.567758  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.665745 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.600791  [    0/   20]\n",
            "loss: 0.614697  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.666397 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.758394  [    0/   20]\n",
            "loss: 0.631992  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.666111 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.520215  [    0/   20]\n",
            "loss: 0.682603  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.665312 \n",
            "\n",
            "Current best validation accuracy: 50.0%\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.820253  [    0/   20]\n",
            "loss: 0.740356  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.661986 \n",
            "\n",
            "Current best validation accuracy: 70.0%\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.671585  [    0/   20]\n",
            "loss: 0.602096  [   10/   20]\n",
            "Validation Error: \n",
            " Accuracy: 90.0%, Avg loss: 0.659462 \n",
            "\n",
            "Current best validation accuracy: 90.0%\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(training_data_loader, model, loss_function, optimizer)\n",
        "    validation(validation_data_loader, model, loss_function)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VWUUt9grNlT"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}